#####################
# Performance Impacting Settings
#####################
fp16 = True

# model specific impact
return_timestamps = False

#####################
# CHANGEABLE SETTINGS
#####################

# Output Directory Name
output_tag = v3_large_feb

# Cluster Specific Settings: These Must Match The Requested Resources In The .BS File
num_workers = 1
cpus_per_trial = 4
gpus_per_trial = 0
use_gpu = False
eval_batch_size = 1
prefetch_batches = 1

# For Reproducibility: Import To Use The Same Random Seed For Evaluation
random_seed = 1337

# resume training
resume_evaluation = True


#####################
# Model type and debugging
#####################
model_type = openai/whisper-large-v3
debug = False
dataset_name = eg_dataset_complete_v3
run_on_local_machine = True
h5 = True
peft = False
path_to_data = "/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/eg_dataset_complete_v3_sharded/test"