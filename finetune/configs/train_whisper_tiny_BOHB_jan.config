#####################
# Performance Impacting Settings
#####################
num_train_epochs = 2
max_warmup_steps = 25
max_concurrent_trials = 5
per_device_train_batch_size = 16
fp16 = True
num_samples = 20
# Trainer/Scheduler Specific Settings
search_schedule_mode = large_small_BOHB
reduction_factor = 4

#####################
# CHANGEABLE SETTINGS BUT NOT RECOMMENDED
#####################
# Output Directory Name
output_tag = whisper_tiny_BOHB_jan
# Logging Specific Settings
save_steps = 50
eval_steps = 25
logging_steps = 10
# Cluster Specific Settings: These Must Match The Requested Resources In The .BS File
cpus_per_trial = 5
gpus_per_trial = 1
# For Reproducibility: Import To Use The Same Random Seed For Evaluation
random_seed = 1337

#####################
# DO NOT CHANGE THESE SETTINGS UNLESS YOU KNOW WHAT YOU ARE DOING
#####################
generation_max_length = 225
model_type = openai/whisper-tiny
path_to_data = datasets
push_to_hub = False
num_workers = 1
use_gpu = True
num_to_keep = 5
