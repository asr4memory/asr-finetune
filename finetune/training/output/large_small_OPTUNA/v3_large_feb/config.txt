Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 15,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': True,
 'logging_steps': 5,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-large-v3',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 30,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 15,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': True,
 'logging_steps': 5,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-large-v3',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 30,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 15,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': True,
 'logging_steps': 5,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': False,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 30,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 15,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': True,
 'logging_steps': 5,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': False,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 30,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 15,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 5,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': False,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 30,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 5,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': False,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 30,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': False,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_size': 20,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_fraction': 0.001,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_t': 10,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_eval_batch_size': 8,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_fraction': 0.001,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_t': 10,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_eval_batch_size': 8,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_fraction': 0.001,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_t': 10,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_eval_batch_size': 8,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


Parsed args:
{'burn_in_period': 1,
 'c': 'configs/largev3_debug.config',
 'cpus_per_trial': 2,
 'data_mode': 'h5',
 'dataloader_num_workers': 1,
 'dataset_name': 'eg_dataset_complete_v3_sharded',
 'debug': True,
 'eval_delay': 0,
 'eval_sample_fraction': 0.001,
 'eval_steps': 1,
 'fp16': True,
 'generation_max_length': 225,
 'gpus_per_trial': 0.0,
 'grace_period': 1,
 'gradient_accumulation_steps': 1,
 'h5': False,
 'hyperparameters': [['learning_rate',
                      'weight_decay',
                      'scheduler',
                      'warmup_steps']],
 'len_train_set': 10,
 'load_ds_in_trainer': False,
 'logging_steps': 1,
 'max_concurrent_trials': 32,
 'max_steps': 100,
 'max_t': 10,
 'max_warmup_steps': 29,
 'metric_to_optimize': [['eval_wer']],
 'model_type': 'openai/whisper-small',
 'modes': [['min']],
 'num_samples': 5,
 'num_to_keep': 1,
 'num_train_epochs': 1,
 'num_workers': 1,
 'output_dir': './output',
 'output_tag': 'v3_large_feb',
 'path_to_data': '/Users/chrvt/Documents/GitHub/asr-finetune/data_example/datasets/',
 'peft': True,
 'per_device_eval_batch_size': 8,
 'per_device_train_batch_size': 8,
 'perturbation_interval': 10,
 'prefetch_batches': 1,
 'random_seed': 1337,
 'reduction_factor': 4,
 'resume_training': False,
 'return_timestamps': False,
 'reuse_actors': True,
 'run_on_local_machine': True,
 'save_steps': 2,
 'search_schedule_mode': 'large_small_OPTUNA',
 'simple': False,
 'storage_path': './output/scratch',
 'target_language': 'german',
 'test_split': 0.2,
 'use_gpu': False}


